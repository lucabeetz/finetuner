{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from finetuner import Client, Finetuner\n",
    "from finetuner.storage import FileStorage\n",
    "from finetuner.eval import Eval\n",
    "\n",
    "from examples.data import SEARCH_CLASSIFIER_USER_INPUTS\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_classifier_template = \"\"\"You are helping an AI assistant decide whether a google search for real-time information is necessary to correctly answer a user's query.\n",
    "For this, you have to output either 'Y' or 'N' depending on the user query below.\n",
    "\n",
    "User query: {user_input}\n",
    "\n",
    "Output:\"\"\"\n",
    "\n",
    "storage = FileStorage(directory=\"example_finetune\")\n",
    "client = Client.for_openai(storage=storage)\n",
    "\n",
    "def search_classifier(user_input: str) -> str | None:\n",
    "    formatted_template = search_classifier_template.format(user_input=user_input)\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        dataset_name=\"search_classifier\",\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_template}],\n",
    "        model=\"gpt-4\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    result = chat_completion.choices[0].message.content\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:57<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for user_input in tqdm(SEARCH_CLASSIFIER_USER_INPUTS):\n",
    "    search_classifier(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_classifier.json\n"
     ]
    }
   ],
   "source": [
    "storage.list_datasets()\n",
    "dataset = storage.get_dataset(\"search_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train: 80, length val: 20\n"
     ]
    }
   ],
   "source": [
    "client = Client.for_anyscale()\n",
    "finetuner = Finetuner(client=client)\n",
    "\n",
    "train_dataset, val_dataset = dataset.split(0.8)\n",
    "print(f\"Length train: {len(train_dataset)}, length val: {len(val_dataset)}\")\n",
    "\n",
    "train_file_id = finetuner.upload_dataset(train_dataset)\n",
    "val_file_id = finetuner.upload_dataset(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started job: eftjob_3m3tnpwgzz1yxr9j9mc7936tik\n"
     ]
    }
   ],
   "source": [
    "if train_file_id and val_file_id:\n",
    "    job = finetuner.start_job(\"meta-llama/Llama-2-7b-chat-hf\", train_file_id, val_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pending'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FineTuningJob(id='eftjob_3m3tnpwgzz1yxr9j9mc7936tik', created_at='2023-12-02T12:29:00.540512+00:00', error=None, fine_tuned_model='meta-llama/Llama-2-7b-chat-hf:luca:HtZ0GwR', finished_at='2023-12-02T12:41:55.623808+00:00', hyperparameters=Hyperparameters(n_epochs=None, context_length=None), model='meta-llama/Llama-2-7b-chat-hf', object=None, organization_id=None, result_files=['file_87wdw243eft7uu3zcqq3vh3gfa'], status='succeeded', trained_tokens=659000, training_file='file_wvtz41i8xrgl4yi4bgpxtnxj7a', validation_file='file_jbxfjh7yjjm2jwtmnatf4kgkpr', creator_id='euser_hxxbfa4r5lbdzpyngnkqgd5cv6'),\n",
       " FineTuningJob(id='eftjob_ttphxq2iha5s66t1l9xbixgvhp', created_at='2023-12-02T11:33:32.922779+00:00', error=None, fine_tuned_model='meta-llama/Llama-2-7b-chat-hf:luca:rHXJuoi', finished_at='2023-12-02T11:45:37.053637+00:00', hyperparameters=Hyperparameters(n_epochs=None, context_length=None), model='meta-llama/Llama-2-7b-chat-hf', object=None, organization_id=None, result_files=['file_q86qp3bfe9w2f5m2md7bmganvh'], status='succeeded', trained_tokens=659000, training_file='file_59h5gkihg8x5i2r7tmjc5pdttl', validation_file='file_6btddrj5247d5hstynw8igfv14', creator_id='euser_hxxbfa4r5lbdzpyngnkqgd5cv6'),\n",
       " FineTuningJob(id='eftjob_aa7t6jqrc2m1lnab7xs41wwa85', created_at='2023-12-02T00:06:52.992757+00:00', error=None, fine_tuned_model='meta-llama/Llama-2-7b-chat-hf:luca:jXfHLCA', finished_at='2023-12-02T01:37:37.525382+00:00', hyperparameters=Hyperparameters(n_epochs=None, context_length=None), model='meta-llama/Llama-2-7b-chat-hf', object=None, organization_id=None, result_files=['file_sj8r2kangg2jiy1s1vvtapukef'], status='succeeded', trained_tokens=191700, training_file='file_sxlgm43k1cqkb75v82q72ypf3f', validation_file=None, creator_id='euser_hxxbfa4r5lbdzpyngnkqgd5cv6'),\n",
       " FineTuningJob(id='eftjob_kuex9j1az583yyx1tgwilswv59', created_at='2023-12-01T23:48:21.048701+00:00', error=None, fine_tuned_model='meta-llama/Llama-2-7b-chat-hf:luca:Uyd77Tx', finished_at='2023-12-02T01:24:36.640875+00:00', hyperparameters=Hyperparameters(n_epochs=None, context_length=None), model='meta-llama/Llama-2-7b-chat-hf', object=None, organization_id=None, result_files=['file_qb8bkhxglzwuek2adjpqwflrcd'], status='succeeded', trained_tokens=191700, training_file='file_sxlgm43k1cqkb75v82q72ypf3f', validation_file=None, creator_id='euser_hxxbfa4r5lbdzpyngnkqgd5cv6')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuner.list_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client.for_anyscale()\n",
    "finetuner = Finetuner(client=client)\n",
    "\n",
    "class SearchClassifierEval(Eval):\n",
    "    def compare(self, prediction, target):\n",
    "        return prediction.strip() == target.strip()\n",
    "\n",
    "eval = SearchClassifierEval(client=client)\n",
    "eval.run(\"meta-llama/Llama-2-7b-chat-hf\", val_dataset, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Y'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = search_classifier_template.format(user_input=\"What is the current Porsche stock price?\")\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": test}],\n",
    "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    temperature=0\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:18<00:00,  1.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client.for_anyscale()\n",
    "\n",
    "class SearchClassifierEval(Eval):\n",
    "    def compare(self, prediction, target):\n",
    "        return prediction.strip() == target.strip()\n",
    "\n",
    "eval = SearchClassifierEval(client=client)\n",
    "eval.run(\"meta-llama/Llama-2-7b-chat-hf:luca:HtZ0GwR\", val_dataset, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
